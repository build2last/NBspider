{
  "name": "Ncspider",
  "tagline": "中文门户网站新闻和评论抓取。Powered by scrapy.",
  "body": "﻿# NCspider  项目简介   \r\n## 中文门户网站新闻和评论抓取。\r\nA Python Project\r\n\r\n### 编写目的\r\n* 获取门户网站原始新闻及评论素材，结构化存储后，为分析舆情提供数据基础。 \r\n* 门户网站新闻有着微博不可替代的一些特点。 \r\n* 请参考配置说明，为了方便展示，可以结合django建立数据库\r\n* 只需要爬虫的话建立database后修改settings.py相应参数就好了\r\n* 对于网页的解析只用了re正则解析（快过Beautiful Soup）\r\n* 爬虫 news 可以单独使用，暂时只提供mysql支持\r\n\r\n## 简单介绍\r\n* 包括新浪新闻门户，腾讯新闻门户，搜狐新闻（移动端)**新闻**以及**评论**\r\n* 每日新闻数量上千，评论数量级数十万\r\n\r\n### 从零开始配置运行环境---Way to insatll scrapy on ubuntu \r\n  1. sudo apt-get install libxml2-dev libxslt1-dev\r\n  2. sudo apt-get install python-dev\r\n  3. sudo apt-get install libssl-dev \r\n  4. sudo apt-get install libffi-dev\r\n  5. pip install -r requirements.txt\r\n\r\n### 数据库使用\r\n  1. 更改**settings.py**适应你的本地化，数据库的相关设置,或者在 pipeline中修改相关参数\r\n  2. 做了一个匹配的Django models模型方便了解,查看[数据模型](https://github.com/build2last/NCspider/blob/master/pubopin/news_opin/models.py)\r\n\r\n### 使用命令\r\n  * /news$ scrapy allstart   即可运行所有爬虫\r\n  * /news$ scrapy crawl sina\r\n  * /news$ scrapy crawl tencent\r\n  * /news$ scrapy crawl sohu\r\n\r\n### 配套系统\r\n    python 2.7\r\n    Mysql \r\n    Scrapy 1.0\r\n    \r\n### 测试\r\n    Linux Ubuntu 14.04 tested\r\n    Windows 10 tested\r\n\r\n## 问题说明：\r\n1. 编码问题：\r\n  * 中文网页：对中文的解析需要特别注意编码问题，utf-8是多数，但有时网站会采用GBK,GBK2312等编码格式。\r\n  * 数据库编码：出现了一大堆乱七八糟的文字，可以怀疑数据库字段编码跟内容编码不一致。\r\n2. 利用django建立数据库时会有一些被默认的参数可能会被忽略，比如说数据项默认为非空 not null = true,所以说：使用前请认真阅读document\r\n\r\n### To do list：\r\n* 抓的更全\r\n* code review，运行更高效\r\n* scrapy是一个优秀的爬虫框架，结构合理，提供多线程，以后随着学习的深入会试着将更多成果运用进来。\r\n* 支持更多数据库类型，包括 NoSQL\r\n* HTML cache\r\n\r\n## 声明\r\n* Email：**lancelotdev@163.com**\r\n* Author：liu kun\r\n* Last-Modified：2016-10\r\n\r\n### project journal\r\n\r\n#### 2016-10-12\r\n项目答辩出奇顺利，因为确实下功夫了，洗澡去了，再见！\r\n\r\n楼下『加油』震天响\r\n\r\n[python]:https://www.python.org/\r\n[scrapy]:http://scrapy.org/\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}